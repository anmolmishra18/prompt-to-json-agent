# ðŸ¤– Prompt â†’ JSON Agent

A small agent that converts free-text or structured prompts into **refined JSON specifications**.  
The agent runs an **evaluation + feedback loop** that improves the spec over multiple iterations.  
Reports and feedback logs are saved automatically.

---

## ðŸš€ Features

- **Prompt to JSON**:  
  Accepts either structured input (`Title: â€¦; Description: â€¦; Owner: â€¦; Requirements: â€¦`) or free text.  

- **Feedback Iterations**:  
  Each iteration runs the evaluator + feedback module to improve the spec until it is complete.  

- **Reports & Logs**:  
  - JSON and TXT reports are saved in `/reports/`.  
  - Feedback history is logged in `/logs/`.  
  - A daily values log (`honesty`, `discipline`, `gratitude`, `integrity`) is appended in `/reports/daily_log.txt`.  

- **Dual Interface**:  
  - Command Line Interface (CLI) via `main.py`.  
  - Streamlit web app via `app.py`.  

---

## ðŸ›  Installation

Clone the repository and install dependencies:

```bash
git clone https://github.com/your-username/prompt-to-json-agent.git
cd prompt-to-json-agent
python -m venv venv
source venv/bin/activate   # On Linux/Mac
venv\Scripts\activate      # On Windows
pip install -r requirements.txt
ðŸ’» Usage
1. CLI Mode
Run with a structured prompt:

bash
Copy code
python main.py --prompt "Title: Student Portal; Description: Manage courses and grades; Owner: Anmol; Requirements: login, dashboard, reports" --iterations 3
Run with a free-text prompt:

bash
Copy code
python main.py --prompt "Make a chatbot for exam queries" --iterations 3
Run with a sample JSON file:

bash
Copy code
python main.py --sample spec1.json --iterations 2
âœ… After each run:

Reports are saved in /reports/.

Feedback logs are saved in /logs/.

The final refined spec is printed to the console.

2. Streamlit App
Launch the web interface:

bash
Copy code
streamlit run app.py
Enter your prompt and choose the number of feedback iterations.
You will see:

The parsed JSON spec.

The final refined spec.

Access to logs and reports.

ðŸ“‚ Project Structure
bash
Copy code
prompt-to-json-agent/
â”‚
â”œâ”€â”€ app.py              # Streamlit UI
â”œâ”€â”€ main.py             # CLI entrypoint + pipeline
â”œâ”€â”€ evaluator/
â”‚   â”œâ”€â”€ criteria.py     # Scoring & evaluation
â”‚   â”œâ”€â”€ feedback.py     # Feedback generation & application
â”‚   â””â”€â”€ report.py       # Report generation (per iteration + final)
â”‚
â”œâ”€â”€ reports/            # Generated reports + daily_log.txt
â”œâ”€â”€ logs/               # Feedback history logs
â”œâ”€â”€ spec1.json          # Sample spec
â”œâ”€â”€ spec2.json          # Sample spec
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ Read.md             # Documentation (this file)
ðŸ§­ Daily Values Log
Each CLI run appends a reflection entry to /reports/daily_log.txt:

pgsql
Copy code
=== 20250827_141530 ===
Integrity: Submitted the work honestly without skipping compulsory steps.
Honesty: Today I tested the pipeline and verified reports/logs.
Discipline: Kept code structured and updated Read.md.
Gratitude: Grateful for having completed all Task 3 steps.
This ensures honesty, discipline, gratitude, and integrity are recorded daily.

